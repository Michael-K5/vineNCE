% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/classifier_methods.R
\name{build_model}
\alias{build_model}
\title{Defines and compiles a neural network for binary classification.
Activation function is leaky_relu, output is one layer with no activation
(to train a binary classifier with from_logits=TRUE option)}
\usage{
build_model(
  input_dim = 5,
  hidden_units = c(20, 10),
  initial_lr = 0.01,
  use_tanh = FALSE,
  leaky_relu_alpha = 0.1
)
}
\arguments{
\item{input_dim}{dimension of the input, defaults to 5}

\item{hidden_units}{vector containing the number of units per layer.
Defaults to c(20,10)}

\item{initial_lr}{initial learing rate to use, defaults to 0.01
(Ã­f no lr_scheduler is used during training, this stays the same during
the whole training process)}

\item{use_tanh}{If TRUE uses tanh activation, otherwise uses leaky_relu.}

\item{leaky_relu_alpha}{slope in the negative part of the relu. Defaults to 0.01.}
}
\value{
the compiled neural network model
}
\description{
Defines and compiles a neural network for binary classification.
Activation function is leaky_relu, output is one layer with no activation
(to train a binary classifier with from_logits=TRUE option)
}
